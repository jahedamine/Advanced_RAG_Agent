{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2645be98",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "# üß† Advanced RAG Agent ‚Äî Documentation Interne\n",
    "Ce notebook construit un agent RAG capable de r√©pondre √† des questions sur une documentation interne, en utilisant FAISS, LangChain LCEL, et Mistral-7B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b42d8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "!pip install -q langchain transformers sentence-transformers faiss-cpu accelerate torch langchain-community fastapi uvicorn pyngrok requests==2.32.4 langchain-huggingface langchain-core langchain-text-splitters deep_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile agent_rag_ngrok.py\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "import threading\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from pyngrok import ngrok\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import uvicorn\n",
    "\n",
    "# --- Authentification Ngrok ---\n",
    "ngrok.set_auth_token(\"YOUR_NGROK_AUTH_TOKEN\")\n",
    "\n",
    "# --- Chargement du corpus ---\n",
    "FILE_PATH = \"documentation_interne.txt\"\n",
    "try:\n",
    "    with open(FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        document_content = f.read()\n",
    "except FileNotFoundError:\n",
    "    raise Exception(f\"Fichier {FILE_PATH} introuvable.\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.create_documents([document_content])\n",
    "\n",
    "# --- Embeddings + Vector Store ---\n",
    "embedding_function = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'}\n",
    ")\n",
    "vector_store = FAISS.from_documents(docs, embedding_function)\n",
    "rag_retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# --- LLM Mistral ---\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=model_id,\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"max_new_tokens\": 512},\n",
    "    device=0,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16}\n",
    ")\n",
    "\n",
    "# --- Prompt + Cha√Æne RAG ---\n",
    "RAG_PROMPT = ChatPromptTemplate.from_template(\"\"\"\n",
    "Tu es un assistant IA professionnel francophone. Utilise UNIQUEMENT le contexte fourni ci-dessous pour r√©pondre √† la question. \n",
    "Si la r√©ponse n'est pas dans le contexte, r√©ponds poliment : 'Je suis d√©sol√©, cette information sp√©cifique n'est pas disponible dans ma documentation interne.'\n",
    "\n",
    "--- CONTEXTE ---\n",
    "{context}\n",
    "--- FIN CONTEXTE ---\n",
    "\n",
    "Question: {question}\n",
    "\"\"\")\n",
    "\n",
    "rag_chain = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: x['question']) | rag_retriever)\n",
    "    | RAG_PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# --- API FastAPI ---\n",
    "app = FastAPI(\n",
    "    title=\"Advanced RAG Agent API\",\n",
    "    description=\"API pour poser des questions sur une documentation interne via RAG + Mistral\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "class Query(BaseModel):\n",
    "    question: str\n",
    "\n",
    "@app.post(\"/ask\")\n",
    "async def ask_question(query: Query):\n",
    "    try:\n",
    "        raw_response = rag_chain.invoke({\"question\": query.question})\n",
    "        if \"Assistant:\" in raw_response:\n",
    "            cleaned = raw_response.split(\"Assistant:\")[-1].strip()\n",
    "        else:\n",
    "            cleaned = raw_response.strip()\n",
    "        # Traduction si la r√©ponse est en anglais\n",
    "        translated = GoogleTranslator(source='auto', target='fr').translate(cleaned)\n",
    "        return {\"answer\": translated}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health_check():\n",
    "    return {\"status\": \"ok\"}\n",
    "\n",
    "@app.get(\"/\")\n",
    "def welcome():\n",
    "    return {\"message\": \"Bienvenue sur l'API RAG. Utilisez /docs pour tester.\"}\n",
    "\n",
    "# --- Lancement Uvicorn + Ngrok ---\n",
    "def launch_api():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "def launch_ngrok():\n",
    "    time.sleep(3)\n",
    "    public_url = ngrok.connect(8000)\n",
    "    print(f\"\\nüîó URL publique de l'API : {public_url}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Lancement de l'agent RAG + API FastAPI + tunnel Ngrok...\")\n",
    "    api_thread = threading.Thread(target=launch_api)\n",
    "    ngrok_thread = threading.Thread(target=launch_ngrok)\n",
    "    api_thread.start()\n",
    "    ngrok_thread.start()\n",
    "    api_thread.join()\n",
    "    ngrok_thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01820fff",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python agent_rag_ngrok.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
